
<h1 id="aws-sysops-associate-exam-notes">AWS SysOps Associate Exam Notes</h1>
<p><br>
<center>
<img src="./logo.png" /> <br>
For more information on AWS, visit <a href="https://aws.amazon.com/">aws.amazon.com</a>
</center></p>
<p><br></p>
<h1 id="description">Description</h1>
<hr />
<p>Notes and information that were collected while studying and prepping for the AWS SysOps Associate Exam. <br>
<br></p>
<table>
<thead>
<tr>
<th>Topic</th>
<th>Answer</th>
</tr>
</thead>
<tbody>
<tr>
<td>Exam Time:</td>
<td>80 Minutes</td>
</tr>
<tr>
<td>No. Questions:</td>
<td>60 Questions</td>
</tr>
<tr>
<td>Question Types:</td>
<td>Scenario and Multiple Choice</td>
</tr>
<tr>
<td>Passing Score:</td>
<td>~ 70%</td>
</tr>
<tr>
<td>Validity Period:</td>
<td>2 years</td>
</tr>
<tr>
<td>Renewal Exam:</td>
<td>1/2 price off</td>
</tr>
</tbody>
</table>
<p><br></p>
<h1 id="monitoring">Monitoring:</h1>
<hr />
<p>Monitoring is accomplished through the usage of CloudWatch, which is a service to monitor your AWS resources as well as the applications that you run on AWS. <br><br></p>
<blockquote>
<p><strong>CloudWatch Monitoring:</strong></p>
</blockquote>
<p><br></p>
<ul>
<li>Can monitor EC2 instances, Autoscaling Groups, ELBs, Route53 Health Checks, EBS Volumes, Storage Gateways, CloudFront, DynamoDB, ElastiCache nodes, RDS instances, EMR Job Flows, Redshift. 
  SNS topics, SQS Queues, OpsWorks, CloudWatch Logs, Estimated charges on your AWS bill, and custom metrics | logs generated by your applications and services. </li>
<li>EC2 will by default monitor your instances @5 minute intervals</li>
<li>EC2 instances can monitor your instances @1 minute intervals if the 'detailed monitoring' option is set on the instance</li>
<li>By default CloudWatch will monitor CPU, Network, Disk, and Status Checks</li>
<li>RAM utilization is a custom metric and must be added manually to EC2 instances in order to be tracked.</li>
<li>2 types of Status Checks:<ul>
<li>System Status Checks (Physical Host):<ul>
<li>Checks the underlying physical host</li>
<li>Checks for loss of network connectivity</li>
<li>Checks for loss of system power</li>
<li>Checks for software issues on the physical host</li>
<li>Checks for hardware issues on the physical host</li>
<li>Best way to resolve issues is to stop the instance and start it again (will switch physical hosts)</li>
</ul>
</li>
<li>Instance Status Checks<ul>
<li>Checks the VM itself</li>
<li>Checks for failed system status checks</li>
<li>Checks for mis-configured networking or startup configs</li>
<li>Checks for exhausted memory</li>
<li>Checks for corrupted file systems</li>
<li>Checks for an incompatible kernel</li>
<li>Best way to troubleshoot is rebooting the instance or modifying the instance OS</li>
</ul>
</li>
</ul>
</li>
<li>By default CloudWatch metrics are stored for 2 weeks</li>
<li>Can retrieve data that is longer than 2 weeks using the GetMetricStatistics API endpoint, or by using third party tools</li>
<li>Can retrieve data from any terminated EC2 or ELB instance for up to 2 weeks after its termination</li>
<li>Many default metrics for many default services are 1 min, but it can be 3-5 minutes depending on the service</li>
<li>Custom metrics have a minimum 1 minute granularity</li>
<li>Alarms can be created to monitor any CloudWatch metric in your account</li>
<li>Alarms can include EC2, CPU, ELB, Latency, or even changes on your AWS bill</li>
<li>Within the alarm, actions can be set, triggering things like lambda functions, or SNS notifications if the alarm threshold is reached</li>
</ul>
<p><br></p>
<blockquote>
<p><a href="https://aws.amazon.com/code/8720044071969977"><strong>Configuring custom metrics:</strong></a></p>
</blockquote>
<p><br></p>
<ul>
<li>In order to allow custom metrics to be written to CloudWatch, you must assign a CloudWatch full access role to the EC2 instance using the custom metrics.</li>
<li>RAM utilization for example must be set up as a custom metric</li>
<li>yum install -y perl-Switch perl-DateTime perl-Sys-Syslog perl-LWP-Protocol-https</li>
<li>mkdir /CloudWatch &amp;&amp; cd /CloudWatch</li>
<li>wget http://aws-cloudwatch.s3.amazonaws.com/downloads/CloudWatchMonitoringScripts-1.2.1.zip</li>
<li>unzip CloudWatchMonitoringScripts-v1.2.1.zip</li>
<li>rm -fr CloudWatchMonitoringScripts-v1.2.1.zip</li>
<li>cd aws-scripts-mon</li>
<li>./mon-put-instance-data.pl --mem-util --verify --verbose (dry run no data will be sent to CloudWatch)</li>
<li>./mon-put-instance-data.pl --mem-util --mem-used --mem-avail (set this up on 1/5 minute cron job)</li>
<li>Set Cron job to run regulary (<em>/5 * </em> * * ec2-user /CloudWatch/mon-put-instance-data.pl --mem-util --mem-used)</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>Monitoring EBS:</strong></p>
</blockquote>
<p><br></p>
<ul>
<li>4 Types of EBS Storage, General Purpose (SSD) - gp2, Provisioned IOPS (SSD) - io1, Throughput Optimized (HDD) - st1, and Cold (HDD) - sc1</li>
<li>Throughput Optimized HDDs (ST1) and Cold HDDs (SC1), both CAN NOT BE USED AS BOOT VOLUMES!</li>
<li>Throughput Optimized HDDs (ST1) and Cold HDDs (SC1), both are not available in the drop list if the volume is the root volume. Adding an additional volume will allow these option types to become present in the drop list. </li>
<li>GP2 volumes have a base of 3 IOPS per GiB of volume size</li>
<li>Maximum volume size is 16 TB</li>
<li>Maximum IOPS size of 10K IOPS total (after which you need to move to provisioned IOPS storage tier)</li>
<li>Can burst performance on the volume up to 3K IOPS</li>
<li>Bursting uses I/O credits</li>
<li>Each volume receives an initial I/O credit balance of 5.4 million I/O credits</li>
<li>This is enough to sustain the max burst performance of 3K IOPS for 30 minutes (3K being the MAX iOPS available, including your standard 3 IOPS per GB. You can not burst an additional 3K to your standard, only burst up to a max of 3K)</li>
<li>If you need more than 3K IOPS then you need to increase the volume size accordingly via the 3 IOPS per GB rule</li>
<li>When not going over provisioned IO level (bursting) you earn credits back</li>
<li>Don't need to know the calculation to replenish the credit balance</li>
<li>New volumes no longer require pre-warming, they receive their maximum performance the moment that they are available and do not require initialization / pre-warming.</li>
<li>When restoring a volume from snapshots, the first time you access the storage block, you can see a 5 to 50 % loss of IOPS due the volume either needing to be wiped clean or instantiated from a snapshot</li>
<li>Performance is restored after the data is accessed once</li>
<li>To avoid the performance hit, volumes can be pre-warmed</li>
<li>For a new volume, you should write to all blocks before using the volume</li>
<li>For a volume that has been restored from a snapshot, you should read all blocks that have data before using the volume</li>
<li>Instructions for pre-warming volumes can be found <a href="http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-initialize.html">here</a></li>
<li>EBS CloudWatch Metrics:<ul>
<li>VolumeReadBytes</li>
<li>VolumeWriteBytes<ul>
<li>Provides info on the I/O operations in a specified period of time</li>
<li>The SUM statistic reports the total number of bytes transferred during the period</li>
<li>The AVG statistic reports the average size of each I/O operation during the period</li>
<li>The SampleCount statistic reports the total number of I/O operations during the period</li>
<li>The Minimum and Maximum statistics are not relevant for this metric</li>
<li>Data is only reported to CloudWatch when the volume is active</li>
<li>If the volume is idle, no data is reported to CloudWatch</li>
</ul>
</li>
<li>VolumeReadOps</li>
<li>VOlumeWriteOps<ul>
<li>The total number of I/O operations in a specified period of time</li>
<li>To calculate the AVG IOPS for the period, divide the total operations in the period by the number of seconds in that period</li>
</ul>
</li>
<li>VolumeTotalReadTime</li>
<li>VolumeTotalWriteTime<ul>
<li>The total number of seconds spent by all operations that completed in a specified period of time</li>
<li>If multiple requests are submitted a the same time, the total could be greater than the length of the period</li>
</ul>
</li>
<li>VolumeIdleTime<ul>
<li>The total number of seconds in a specified period of time when no read or write operations were submitted</li>
</ul>
</li>
<li>VolumeQueueLength<ul>
<li>Then number of read and write operation requests waiting to be completed in a specified period of time</li>
<li>If the count is high, it would be a good indicator to up the volume size to get more IOPS available via the 3 IOPS per GiB rule</li>
</ul>
</li>
<li>VolumeThroughputPercentage<ul>
<li>Used with Provisioned IOPS (SSD) volumes only</li>
<li>The percentage of IOPS delivered of the total IOPS provisioned for an EBS volume</li>
<li>Provisioned IOPS SSD volumes deliver within 10% of the provisioned IPS performance 99.9% of the time over a given year</li>
<li>During a write, if there are no other pending I/O requests in a minute, the metric value will be 100%</li>
<li>A volume's I/O performance may become degraded temporarily due to an action that was taken (such as creating a snapshot of a volume during peak usage, or running the volume on a non-EBS-optimized instance, or accessing data on the volume for the first time, if the volume wasn't pre-warmed)</li>
</ul>
</li>
<li>VolumeConsumedReadWriteOps<ul>
<li>Used with Provisioned IOPS (SSD) volumes only</li>
<li>The total amount of read and write operations (normalized to 256K capacity units) consumed in a specified period of time</li>
<li>I/O operations that are smaller than 256K each count as 1 consumed IOPS</li>
<li>I/O operations that are larger than 256K are counted in 256K capacity units</li>
</ul>
</li>
</ul>
</li>
<li>VolumeQueueLength can come up frequently, know what it is</li>
<li>Volume Status Checks:<ul>
<li>OK:<ul>
<li>I/O Enabled status:<ul>
<li>Enabled (I/O Enabled or I/O Auto-Enabled)</li>
</ul>
</li>
<li>I/O Performance Status:<ul>
<li>Only available for Provisioned IOPS (IO1) volumes</li>
<li>Normal (Volume performance is as expected)</li>
</ul>
</li>
</ul>
</li>
<li>Warning:<ul>
<li>I/O Enabled status:<ul>
<li>Enabled (I/O Enabled or I/O Auto-Enabled)</li>
</ul>
</li>
<li>I/O Performance Status:<ul>
<li>Only available for Provisioned IOPS (IO1) volumes</li>
<li>Degraded (Volume performance is below expectations)</li>
</ul>
</li>
</ul>
</li>
<li>Impaired:<ul>
<li>I/O Enabled status:<ul>
<li>Enabled (I/O Enabled or I/O Auto-Enabled)</li>
<li>Disabled (volume is off-line and pending recovery, or is waiting for the user to enable I/O)</li>
</ul>
</li>
<li>I/O Performance Status:<ul>
<li>Only available for Provisioned IOPS (IO1) volumes</li>
<li>Stalled (Volume performance is severely impacted)</li>
</ul>
</li>
</ul>
</li>
<li>Insufficient Data:<ul>
<li>I/O Enabled status:<ul>
<li>Enabled (I/O Enabled or I/O Auto-Enabled)</li>
<li>Insufficient Data</li>
</ul>
</li>
<li>I/O Performance Status:<ul>
<li>Only available for Provisioned IOPS (IO1) volumes</li>
<li>Insufficient Data</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Degraded, Severely Degraded = Warning</li>
<li>Stalled or Not Available = Impaired</li>
<li>If your EBS volume is attached to a current generation EC2 instance type, you can increase its size, change its volume type, or adjust its IOPS performance without detaching it</li>
<li>These changes can be applied to detached volumes as well</li>
<li>From the console (Volumes Console, Not EC2 Console), or from the API, Volumes can be modifed.</li>
<li>When modifying a volume, you can monitor the progress of the modification. If the size of the volume was modified, be sure to extend the volumes file system to take advantage of the increased capacity.</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>Monitoring RDS:</strong></p>
</blockquote>
<p><br></p>
<ul>
<li>2 types of monitoring:<ul>
<li>Monitor by metrics (CloudWatch monitoring):<ul>
<li>Per-Database Metrics</li>
<li>By Database Class</li>
<li>By Database Engine</li>
<li>Across All Databases</li>
</ul>
</li>
<li>Monitor by events (RDS monitoring):<ul>
<li>Located in Events tab</li>
<li>Events of everything that has happened with your instance</li>
<li>Can set event subscriptions which work like SNS topics</li>
<li>Events like fail-overs can be a notifying event using subscriptions</li>
<li>Available RDS Metrics:<ul>
<li>BinLogDiskUsage</li>
<li>The amount of disk space occupied by binary logs on the master. Applies to MySQL read replicas</li>
<li>Units: Bytes</li>
<li>Burst Balance</li>
<li>The percent of General Purpose SSD (gp2) burst-bucket I/O credits available</li>
<li>Units: Percent</li>
<li>CPUUtilization</li>
<li>The percentage of CPU utilization.</li>
<li>Units: Percent</li>
<li>CPUCreditUsage (T2 Instances)</li>
<li>The number of CPU credits consumed by the instance</li>
<li>One CPU credit equals one vCPU running at 100% utilization for one minute or an equivalent combination of vCPUs, utilization, and time</li>
<li>Example: one vCPU running at 50% utilization for two minutes or two vCPUs running at 25% utilization for two minutes</li>
<li>Units: Count</li>
<li>CPUCreditBalance (T2 Instances)</li>
<li>The number of CPU credits available for the instance to burst beyond its base CPU utilization</li>
<li>Credits are stored in the credit balance after they are earned and removed from the credit balance after they expire</li>
<li>Credits expire 24 hours after they are earned</li>
<li>CPU credit metrics are available only at a 5 minute frequency</li>
<li>Units: Count</li>
<li>DatabaseConnections</li>
<li>The number of database connections in use</li>
<li>Units: Count</li>
<li>DiskQueueDepth</li>
<li>The number of outstanding IOs (read/write requests) waiting to access the disk</li>
<li>Units: Count</li>
<li>FreeableMemory</li>
<li>The amount of available random access memory</li>
<li>Units: Bytes</li>
<li>FreeStorageSpace</li>
<li>The amount of available storage space</li>
<li>Units: Bytes</li>
<li>MaximumUsedTransactionIDs</li>
<li>The maximum transaction ID that has been used. Applies to PostgreSQL</li>
<li>Units: Count</li>
<li>ReplicaLag (Seconds)</li>
<li>The amount of time a Read Replica DB instance lags behind the source DB instance. Applies to MySQL, MariaDB, and PostgreSQL Read Replicas</li>
<li>Units: Seconds</li>
<li>ReplicationSlotDiskUsage</li>
<li>The disk space used by replication slot files. Applies to PostgreSQL</li>
<li>Units: Megabytes</li>
<li>OldestReplicationSlotLag</li>
<li>The lagging size of the replica lagging the most in terms of WAL data received. Applies to PostgreSQL</li>
<li>Units: Megabytes</li>
<li>TransactionLogsDiskUsage</li>
<li>The disk space used by transaction logs. Applies to PostgreSQL</li>
<li>Units: Megabytes</li>
<li>TransactionLogsGeneration</li>
<li>The size of transaction logs generated per second. Applies to PostgreSQL</li>
<li>Units: Megabytes/second</li>
<li>SwapUsage</li>
<li>The amount of swap space used on the DB instance</li>
<li>Units: Bytes</li>
<li>ReadIOPS</li>
<li>The average number of disk I/O operations per second</li>
<li>Units: Count/Second</li>
<li>WriteIOPS</li>
<li>The average number of disk I/O operations per second</li>
<li>Units: Count/Second</li>
<li>ReadLatency</li>
<li>The average amount of time taken per disk I/O operation</li>
<li>Units: Seconds</li>
<li>WriteLatency</li>
<li>The average amount of time taken per disk I/O operation</li>
<li>Units: Seconds</li>
<li>ReadThroughput</li>
<li>The average number of bytes read from disk per second</li>
<li>Units: Bytes/Second</li>
<li>WriteThroughput</li>
<li>The average number of bytes written to disk per second</li>
<li>Units: Bytes/Second</li>
<li>NetworkReceiveThroughput</li>
<li>The incoming (Receive) network traffic on the DB instance, including both customer database traffic and Amazon RDS traffic used for monitoring and replication</li>
<li>Units: Bytes/second</li>
<li>NetworkTransmitThroughput</li>
<li>The outgoing (Transmit) network traffic on the DB instance, including both customer database traffic and Amazon RDS traffic used for monitoring and replication</li>
<li>Units: Bytes/second</li>
</ul>
</li>
<li>Have general idea of what each of the RDS metrics do</li>
<li>DatabaseConnections, DiskQueueDepth, FreeStorageSpace, ReplicaLag (Seconds), ReadIOPS, WriteIOPS, ReadLatency, WriteLatency are all important ones to know</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>Monitoring ELB:</strong></p>
</blockquote>
<p><br></p>
<ul>
<li>Monitored every 60 seconds provided there is traffic</li>
<li>Only reports when requests are flowing through the LB</li>
<li>If there are no requests or data for a given metric, the metric will not be reported to CloudWatch</li>
<li>If there are requests flowing through the LB, ELB will measure and send metrics for that LB in 60 second intervals</li>
<li>Available Metrics:<ul>
<li>HealthyHostCount:<ul>
<li>The count of the number of healthy instances in each AZ</li>
<li>Hosts are declared healthy if they meet the threshold for the number or consecutive health checks that are successful</li>
<li>Hosts that have failed more health checks then the value of the unhealthy threshold are considered unhealthy</li>
<li>If cross-zone is enabled, the count of the number of healthy instances is calculated for all AZs</li>
<li>Preferred Statistic: Average</li>
</ul>
</li>
<li>UnHealthyHostCount:<ul>
<li>The count of the number of unhealthy instances in each AZ</li>
<li>Hosts that have failed more health cheeks than the value of the unhealthy threshold are considered unhealthy</li>
<li>If cross-zone is enabled, the count of the number of unhealthy instances is calculated for all AZs</li>
<li>Instances may become unhealthy due to connectivity issues, health checks returning non-200 responses (in the case of HTTP or HTTPS health checks), or timeouts when performing the health check</li>
<li>Preferred Statistic: Average</li>
</ul>
</li>
<li>RequestCount:<ul>
<li>The count of the number of completed requests that were received and routed to the back end instances</li>
<li>Preferred Statistic: Sum</li>
</ul>
</li>
<li>Latency:<ul>
<li>Measures the time elapsed in seconds after the request leaves the load balancer until the response is received</li>
<li>Preferred Statistic: Average</li>
</ul>
</li>
<li>HTTPCode_ELB_4XX<ul>
<li>The count of the number of HTTP 4XX client error codes generated by the load balancer when the listener is configured to use HTTP or HTTPS protocols. Client errors are generated when a request is malformed or is incomplete</li>
<li>Preferred Statistic: Sum</li>
</ul>
</li>
<li>HTTPCode_ELB_5XX<ul>
<li>The count of the number or HTTP 5XX server error codes generated by the load balancer when the listener is configured to use HTTP or HTTPS protocols</li>
<li>This metric does not include any responses generated by back end instances</li>
<li>The metric is reported if there are no back-end instances that are healthy or registered to the load balancer, or if the request rate exceeds the capacity of the instances or the load balancers</li>
<li>Preferred Statistic: Sum</li>
</ul>
</li>
<li>HTTPCode_Backend_2XX:</li>
<li>HTTPCode_Backend_3XX:</li>
<li>HTTPCode_Backend_4XX:</li>
<li>HTTPCode_Backend_5XX:<ul>
<li>The count of the number of HTTP response codes generated by back-end instances</li>
<li>Metric does not include any response codes generated by the load balancer</li>
<li>The 2XX class status codes represent successful actions</li>
<li>The 3XX class status codes indicate that the user agent requires action</li>
<li>The 4XX class status code represents client errors</li>
<li>The 5XX class status code represents back-end server errors</li>
<li>Preferred Statistic: Sum</li>
</ul>
</li>
<li>BackendConnectionErrors:<ul>
<li>The count of the number of connections that were not successfully established between the LB and the registered instances</li>
<li>The LB will retry when there are connection errors, so the count can exceed the request rate</li>
<li>Preferred Statistic: Sum</li>
</ul>
</li>
<li>SurgeQueueLength:<ul>
<li>A count of the total number of requests that are pending submission to a registered instance</li>
<li>Preferred Statistic: Max</li>
</ul>
</li>
<li>SpilloverCount:<ul>
<li>A count of the total number of requests that were rejected due to the queue being full</li>
<li>Preferred Statistic: Sum</li>
</ul>
</li>
</ul>
</li>
<li>Have an idea of what each metric does</li>
<li>Important metrics to note are SurgeQueueLength &amp; SpilloverCount</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>Monitoring Elasticache:</strong></p>
</blockquote>
<p><br></p>
<ul>
<li>Consists of 2 different engines:<ul>
<li>Memcached</li>
<li>Redis</li>
</ul>
</li>
<li>When it comes to monitoring cache engines, there are 4 monitoring points:<ul>
<li>CPU Utilization<ul>
<li>Memcached:</li>
<li>Multi-threaded</li>
<li>Handles loads of up to 90% CPU utilization</li>
<li>If &gt; 90% CPU utilization add more nodes to the cluster</li>
<li>Redis:</li>
<li>Single-threaded</li>
<li>Take 90% and / number of cores to determine scale point</li>
<li>Will not have to calculate Redis CPU utilization in exam</li>
</ul>
</li>
<li>Swap Usage</li>
<li>Memcached:<ul>
<li>Should be around 0 most of the time and should not exceed 50MB</li>
<li>If 50MB is exceeded, you should increase the memecached_connections_overhead parameter</li>
<li>memecached_connections_overhead defines the amount of memory to be reserved for Memcached connections and other misc. overhead</li>
</ul>
</li>
<li>Redis<ul>
<li>No SwapUsage metric, instead use reserved-memory</li>
</ul>
</li>
<li>The amount of the Swap file that is used. </li>
<li>Swap file is the amount of disk storage space reserved on disk if your computer runs out of RAM</li>
<li>Typically the size of the swap file = the amount of RAM available</li>
<li>Evictions</li>
<li>Memcached:<ul>
<li>No recommended setting</li>
<li>Choose a threshold based off your application</li>
<li>Scale up (increase the memory of existing nodes) or Scale out (add more nodes) to avoid evictions</li>
</ul>
</li>
<li>Redis:<ul>
<li>No recommended setting</li>
<li>Choose a threshold based off your application</li>
<li>Only scale out (add read replicas) to avoid evictions</li>
</ul>
</li>
<li>Like clowns stuffed in a car, There is a finite number of empty seats that slowly fill up. Eventually the car is full and if more seats are needed, then an Eviction will occur</li>
<li>Evictions occur when a new item is added and an old item must be removed due to lack of free space on the system</li>
<li>Concurrent Connections</li>
<li>No recommended setting</li>
<li>Choose a threshold based off your application</li>
<li>If there is a large and sustained spike in the number of concurrent connections, this can either mean a large traffic spike or your application is not releasing connections efficiently</li>
</ul>
</li>
</ul>
<p><br></p>
<h1 id="organizations-consolidated-billing">Organizations &amp; Consolidated Billing:</h1>
<hr />
<p>AWS Organizations is an account management service that enables you to consolidate multiple AWS accounts into an organization that you create and centrally manage <br><br></p>
<blockquote>
<p><strong>Consolidated Billing:</strong></p>
</blockquote>
<ul>
<li>Have a single payer account</li>
<li>Have multiple linked accounts that all roll up to the payer account for billing purposes</li>
<li>Payer account is independent and cannot access resources of any linked account</li>
<li>Linked accounts are also independent and cannot access resources in any of the other linked accounts, or the payer account</li>
<li>Currently there is a limit of 20 linked accounts for consolidated billing, unless a limit increase is requested</li>
<li>Advantages include a single bill per AWS account, easy way to track charges and allocate costs, and volume pricing discount availability</li>
<li>Always enable MFA on root account, always use strong and complex passwords on the root account, Payer account should be used for billing purposes only, do not deploy resources in the payer account</li>
<li>When monitoring is enabled on the payer account, the billing data for all linked accounts is also included</li>
<li>You can still create billing alerts per individual accounts as well</li>
<li>CloudTrail is per AWS account and is enabled per region</li>
<li>CloudTrail can be aggregated in to a single bucket in the payer account</li>
<li>Consolidated billing allows you to get volume discounts on all of your accounts</li>
<li>Unused reserved instances for EC2 are applied across the group</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>Cost Optimization:</strong></p>
</blockquote>
<ul>
<li>3 different instance types:</li>
<li>Spot<ul>
<li>Allow you to name your own price for EC2 capacity</li>
<li>You bid on spare EC2 instances and these will run automatically whenever your bid exceeds the current spot price</li>
<li>Spot price varies in real time based on supply and demand</li>
<li>If the spot price goes above your bid price after the instances are provisioned, the instances will be automatically terminated</li>
</ul>
</li>
<li>Reserved Instances<ul>
<li>Provide you with up to 75% discount as compared to on-demand pricing</li>
<li>You are assured that your RI will always be available for the OS and AZ in which you purchased it</li>
<li>For applications that have steady state needs, RIs provide significant savings compared to using on-demand instances</li>
<li>RI's and On-demand instances perform identically. </li>
</ul>
</li>
<li>On Demand<ul>
<li>Pay for compute capacity by the hour with no long term commitments or upfront payments</li>
<li>Increase or decrease your compute capacity depending on the demands of your application and only pay the specified hourly rate for the instances that you use</li>
<li>EC2 always strives to have enough capacity to meet customer needs, but during high periods of high demand, it is possible that you may not be able to launch specific instance types in specific AZs</li>
</ul>
</li>
</ul>
<p><br></p>
<h1 id="elasticity-and-scalability">Elasticity and Scalability:</h1>
<hr />
<p>Elasticity is focused around being able to scale your infrastructure up, and down automatically based on traffic, where Scalability is focused on scaling your infrastrucure out more permanentlty.
- Elasticity 
  - Allows you to stretch out and retract your infrastructure based on demand
  - Pay for only what you need
  - Used during a short time period, such as hours or days
  - EC2:
    - Increase instance sizes as required using RIs
  - DynamoDB
    - Increase additional IOPS for additional spikes in traffic, then decrease IOPS after the spike
  - RDS
    - Not elastic, can't scale RDS based on demand</p>
<ul>
<li>Scalability</li>
<li>Used to talk about building out the infrastructure to meet your demands long term</li>
<li>Used over a longer time period such as weeks, days months and years</li>
<li>EC2:<ul>
<li>Increase the number of EC2 instances based on Autoscaling</li>
</ul>
</li>
<li>DynamoDB<ul>
<li>Unlimited amount of storage</li>
</ul>
</li>
<li>
<p>RDS</p>
<ul>
<li>Increase instance size from small to medium</li>
</ul>
</li>
<li>
<p>Scale UP vs Scale Out</p>
</li>
<li>Scale Up<ul>
<li>Increase the number of CPUs, RMA, or the amount of storage</li>
<li>EC2: increase the instance type from say a T1.micro to T2.small or T2.medium, etc.. </li>
<li>If questions appear to be network related, then its probably a scale up answer</li>
</ul>
</li>
<li>Scale Out<ul>
<li>Add more resources such as web servers</li>
<li>EC2: add additional EC2 instances and Autoscaling</li>
<li>If questions appear to be in relation to not having enough resources, then its probably a scale out answer.</li>
</ul>
</li>
</ul>
<p><br></p>
<h1 id="rds-multi-availability-zones-failover">RDS Multi Availability Zones &amp; Failover:</h1>
<hr />
<blockquote>
<p>Multi AZ Deployment:</p>
</blockquote>
<ul>
<li>Multi AZ deployments for MySQL, PostgreSQL, and Oracle engines utilize synchronous physical replication to keep data on the standby up to date with the primary</li>
<li>Multi AZ deployments for the MSSQL Server engine uses synchronous logical replication to achieve the same result, employing SQL Server native mirroring technology</li>
<li>Both approaches safeguard your data in the event of a DB instance failure or loss of an AZ</li>
<li>Failovers are handled via DNS moves from a primary to secondary instances on the backend</li>
<li>During a failover your connection URL string does not change</li>
<li>High Availability:</li>
<li>Backups are taken from secondary which avoids I/) suspension to the primary</li>
<li>Restores are taken from the secondary which avoids I/o suspensions to the primary</li>
<li>You can force a failover from one AZ to another by rebooting your instance. This can be done from the AWS management console or by using the RebootDBInstance API Call</li>
<li>RDS Multi AZ failover is NOT A SCALING SOLUTION</li>
<li>Read Replicas are used to scale only</li>
</ul>
<p><br></p>
<blockquote>
<p>Read Replicas:</p>
</blockquote>
<ul>
<li>MySQL, PostgreSQL, MariaDB</li>
<li>Amazon uses these engines native asynchronous replication to update the read replica</li>
<li>Aurora</li>
<li>Not yet covered by the exam</li>
<li>Not using Asynchronous replication</li>
<li>Uses an SSD backed virtualized storage layer purpose built for DB workloads</li>
<li>Aurora replicas share the same underlying storage as the source instance</li>
<li>
<p>Using same storage lowers cost and avoids the need to copy data to the replica nodes over the network</p>
</li>
<li>
<p>Make it easy to take advantage of supported engines built in replication functionality</p>
</li>
<li>Used to elastically scale out beyond the capacity constraints of a single DB instance for read heavy workloads</li>
<li>You can create a read replica within a few clicks in the AWS management console</li>
<li>Can also create a read replica with the CreateDBInstanceReadReplica API call</li>
<li>Once the read replica is created, database updates on the source DB instance will be replicated using a supported engines native asynchronous replication</li>
<li>Can create multiple read replicas for a given source DB instance and distribute your applications read traffic among them</li>
<li>
<p>Can have up to 5 read replicas for any 1 primary db instance</p>
</li>
<li>
<p>When to use Read Replicas:</p>
</li>
<li>Scaling beyond the compute or I/O capacity of a single DB instance for read heavy database workloads</li>
<li>The access read traffic can be directed to one or more read replicas</li>
<li>Serving read traffic while the source DB instance is unavailable</li>
<li>If your source DB instance cannot take I/O requests, you can direct read traffic to your read replicas</li>
<li>Commonly used for business reporting or data warehousing scenarios</li>
<li>
<p>Reports or data warehousing queries are typically ran against read replicas instead of the primary production DB instance</p>
</li>
<li>
<p>Creating a read replica</p>
</li>
<li>AWS takes a snapshot of your database</li>
<li>If Multi AZ is not enabled, the snapshot will be of the primary database and can cause brief I/O suspension for around 1 minute</li>
<li>
<p>If Multi AZ is enabled, then snapshots will be taken of the secondary database and there will be no performance impact on your primary db</p>
</li>
<li>
<p>Connecting to a read replica</p>
</li>
<li>Read replicas have a new DNS a record created that should be used to directly access the read replica when the read replica is created</li>
<li>You can promote a read replica to its own standalone db. </li>
<li>
<p>Doing this will break the replication link between the primary and secondary db</p>
</li>
<li>
<p>Read Replica Tips:</p>
</li>
<li>Can have up to 5 read replicas for MySQL, PostgreSQL, and MariaDB</li>
<li>Can have read replicas in different regions for all engines</li>
<li>Replication is asynchronous only not synchronous</li>
<li>Read replicas can be built off Multi AZ DBs</li>
<li>Read replicas themselves cannot be Multi AZ currently</li>
<li>Can have read replicas of read replicas, but beware of latency</li>
<li>DB snapshots and automated backups cannot be taken of read replicas</li>
<li>Key metric is ReplicaLag</li>
<li>Know differences between read replicas and Multi AZ RDS instances</li>
</ul>
<p><br></p>
<blockquote>
<p>RDS Multi AZ and Read Replicas:</p>
</blockquote>
<ul>
<li>When you delete an RDS database, the default action will be set to take a final snapshot, this can be over-ridden with a drop down on the delete screen in the AWS management console</li>
<li>DB Instance Identifiers which are created during the creation of an RDS instance must be unique withing the same AWS account for each RDS instance created</li>
<li>Instance Identifier is the name of the database instance, not the database name, which is specified on a separate view when creating in the AWS management console</li>
<li>Can now Enable IAM DB authentication, which will allow you to control authentication into DB instances via IAM users and groups</li>
<li>Cannot create a read replica initially because no snapshot is present, must take a snapshot in order to create a read replica</li>
<li>Multi AZ can be turned on from a standalone. This can be done via a snapshot and restore, or you can modify an existing RDS instance, and change the Multi AZ Deployment drop option from No to Yes</li>
<li>Modifying the database will take the database off line while it applies its modifications</li>
<li>Modifying or changing an existing db will not change the DNS record</li>
<li>Creating a new instance from an existing snapshot will provision a new DNS record</li>
<li>
<p>In order to create a read replica of a read replica, Database backups must be turned on (or a snapshot must exist)</p>
</li>
<li>
<p>RDS Tips</p>
</li>
<li>Know the difference between read replicas and Multi AZ (scale out vs DR)</li>
<li>If you can't create a read replica you most likely have disabled db backups, change it and turn it on</li>
<li>you can create read replica of read replica's in multiple regions</li>
<li>you can modify the DB itself or create a new database from a snapshot</li>
<li>Endpoints DO NOT CHNAGE if you modify a db, they will change if you create a new d from a snap or if you create a read replica</li>
<li>You can manually fail over a multi AZ DB from one AZ to another by rebooting it</li>
</ul>
<p><br></p>
<h1 id="connectivity-and-troubleshooting">Connectivity and Troubleshooting:</h1>
<hr />
<blockquote>
<p><strong>Connectivity:</strong></p>
</blockquote>
<ul>
<li>Bastion hosts serve as a more secure way to connect to your VPC and AWS Infrastructure components</li>
<li>Bastion hosts act as a gateway between you and your EC2 instances</li>
<li>Bastion hosts help reduce attack vectors on your infrastructure and means that you only have to harden 1-2 EC2 instances as opposed to the entire fleet</li>
<li>1 subnet = 1 AZ, a single subnet cannot span more than 1 Availability Zone</li>
<li>Bastion hosts are used by allowing SSH/RDP connections directly to the hosts, and only those hosts are allowed to SSH/RDP into the rest of your EC2 instances</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>High Availability Troubleshooting:</strong></p>
</blockquote>
<ul>
<li>Things to look for if your instances are not launching into an Autoscaling group:</li>
<li>Associated Key Pair does not exist</li>
<li>Security Group does not exist</li>
<li>Autoscaling config is not working correctly</li>
<li>Autoscaling group not found</li>
<li>Instance type specified is not supported in the AZ</li>
<li>Invalid EBS device mapping</li>
<li>Autoscaling service is not enabled on your account</li>
<li>Attempting to attach EBS block device to an instance store AMI</li>
</ul>
<p><br></p>
<h1 id="elastic-load-balancers">Elastic Load Balancers:</h1>
<hr />
<blockquote>
<p><strong>Root Access:</strong></p>
</blockquote>
<ul>
<li>The following services still allow root access to the hosts provisioned by the corresponding services:</li>
<li>Elastic Beanstalk</li>
<li>Elastic MapReduce</li>
<li>OpsWorks</li>
<li>EC2</li>
<li>ECS</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>ELB Configurations:</strong></p>
</blockquote>
<ul>
<li>You can use ELBs or Elastic Load Balancers to load balance across different AZ's within the same region, but not to different regions or different VPC's themselves</li>
<li>An ELB is different than a NAT</li>
<li>Can have 2 types of ELBs:</li>
<li>External ELB's with External DNS names</li>
<li>Internal ELB's with Internal DNS names</li>
<li>Health checks can be configured to check backend services via protocols such as HTTP/HTTPS</li>
<li>Health check intervals are calculated by multiplying the Health Check Interval x Healthy or Unhealthy Threshold value.</li>
<li>In the example that the HC Interval is 30 sec, and the Threshold is set to 2, after 2 30 second cycles or 1 minute the host will be marked unhealthy</li>
<li>Supports Sticky Sessions:</li>
<li>Not enabled by default</li>
<li>By default the ELB routes each request independently to the application with the smallest amount of load</li>
<li>The sticky session feature (session affinity) enables the ELB to lock a user down to a specific web server (EC2 instance)</li>
<li>All requests at that point from the user during the session are always sent to the same server</li>
<li>To manage sessions, determine how long your ELB should consistently route the user's request to the same application server</li>
<li>2 Types of session stickiness:<ul>
<li>Duration based:</li>
<li>Most commonly used</li>
<li>The ELB creates a session cookie</li>
<li>When the ELB receives a request, it checks to see if this cookie is present in the request. </li>
<li>If the cookie is present, then the request is sent to the server specified in the cookie.</li>
<li>If the cookie is not present, the ELB chooses a backend server based on the existing load balancing algorithm and adds a new cookie to the response</li>
<li>The stickiness policy config defines the cookie expiration, which establishes the duration of validity for each cookie</li>
<li>The cookie is automatically updated after the duration expires.</li>
<li>If the backend sever fails or becomes unhealthy, the ELB stops routing requests to it and instead chooses a new instance based on the selected algorithm</li>
<li>In the event of failure, the request is routed to the new instance as if there is no cookie and the session is no longer sticky</li>
<li>Application controlled:</li>
<li>The ELB uses a special cookie to associate the session with the original server that handled the request, but follows the lifetime of the 
    application generated cookie corresponding to the cookie name specified in the policy configuration</li>
<li>The ELB only inserts a new stickiness cookie if the application response includes a new application cookie</li>
<li>The ELB stickiness cookie does not update with each request</li>
<li>If the ELB stickiness cookie is explicitly removed or expires, the session stops being sticky until a new application cookie is issued</li>
<li>If an application instance fails or becomes unhealthy, the ELB stops routing requests to that instance, and instead chooses a new healthy instance
    based on the existing load balancing algorithm</li>
<li>The ELB will treat the session as now stuck to the new healthy instance and continue routing requests to that instance even if the failed instance comes back online</li>
<li>It is up to the new application instance whether and how to respond to a session which it has not previously seen</li>
</ul>
</li>
<li>ELB Metrics:<ul>
<li>HealthyHostCount - The number of healthy instances in each AZ. Hosts are declared healthy if they meet the threshold for the number of consecutive health checks that
  are successful. Hosts that have failed more health checks then the value of the unhealthy threshold are considered unhealthy. If cross-zone is enabled, the count of 
  the number of healthy instances is calculated for all AZ's. The preferred statistic is the average</li>
<li>UnHealthyHostCount - The count of the the number of unhealthy instances in each AZ. Hosts that have failed more health checks then the value of the unhealthy threshold
  are considered unhealthy. If cross-zone is enabled the count of the number of unhealthy instances is calculated for all AZ's. Instances may become unhealthy due to 
  connectivity issues, health checks returning non 200 responses (in the case of HTTP or HTTPS health checks), or timeouts when performing the health check.
  The preferred statistic is the average</li>
<li>RequestCount - The count of the number of completed requests that were received and routed to the back end instances. The preferred statistic is the sum</li>
<li>Latency - Measures the time elapsed in seconds after the request leaves the ELB until the response is received. The Preferred statistic is the average</li>
<li>HTTPCode_ELB_4XX - The count of the number of 4XX client error codes generated by the load balancer when the listener is configured to use HTTP or HTTPS.
  Client errors are generated when a request is malformed or incomplete. The preferred statistic is the sum</li>
<li>HTTPCode_ELB_5XX - The count of the number of HTTP 5XX server error codes generated by the load balancer when the listener is configured to use HTTP or HTTPS.
  This metric does not include any responses generated by back end instances. The metric is reported if there are no back end instances that are healthy or registered
  to the load balancer, or if the request rate exceeds the capacity of the instances or the load balancers. The preferred statistic is sum</li>
<li>HTTPCode_Backed_2/3/4/5XX - The count of the number of HTTP response codes generated by back end instances. This metric does not include any response codes generated
  by the load balancer. The 2XX class status codes represent successful actions. The 3XX status codes indicate that the user agent requires action. The 4XX class status
  codes represent client errors, and the 5XX class status codes represents back end instance errors. The preferred statistic is sum</li>
<li>BackendConnectionErrors - The count of the number of connections that were not successfully established between the load balancer and the registered instances.
  Because the load balancer will retry when there are connection errors, this count can exceed the request rate. The preferred statistic is sum</li>
<li>SurgeQueueLength - The count of the total number of requests that are pending submission to a registered instance. The preferred statistic is max</li>
<li>SpilloverCount - A count of the total number of requests that were rejected due to the queue being full. The preferred statistic is sum</li>
<li>Pay attention to SurgeQueueLength and SpilloverCount</li>
</ul>
</li>
<li>Pre Warming ELB's:<ul>
<li>AWS can pre-configure the ELB to have the appropriate level of capacity based on expected traffic</li>
<li>Used in scenarios such as when flash traffic is expected, or in the case where a load test cannot be configured to gradually increase traffic</li>
<li>This can be done by contacting AWS prior to the expected event. You will need to know the following:</li>
<li>The start and end date of the expected flash traffic</li>
<li>The expected request rate per second</li>
<li>The total size of the typical request/response that you will be sending/receiving</li>
</ul>
</li>
</ul>
<p><br></p>
<h1 id="backups-and-disaster-recovery">Backups and Disaster Recovery:</h1>
<hr />
<blockquote>
<p><strong>Disaster Recovery:</strong></p>
</blockquote>
<ul>
<li>DR is about preparing for and recovering from a disaster</li>
<li>Any event that has a negative impact on a company's business continuity or finances could be termed a disaster</li>
<li>Disasters include software, hardware, network failures, power outages, physical damage to buildings like fire or flooding, human error, etc..</li>
<li>Traditional approaches involve an N+1 approach and have different levels of off-site duplication of data and/or infrastructure</li>
<li>Advantages of using AWS for DR</li>
<li>Only minimum hardware is required for data replication</li>
<li>Allows you flexibility depending on what your disaster is and how to recover from it</li>
<li>Open cost model (pay as you use) rather than heavy investment upfront</li>
<li>Scaling is quick and easy</li>
<li>Automate infrastructure for DR deployments</li>
<li>AWS storage Gateways:</li>
<li>Gateway cached volumes store primary data and cache most recently used data locally</li>
<li>Gateway stored volumes store entire datasets on site and asynchronously replicate data back to S3</li>
<li>Gateway virtual tape libraries store your virtual tapes in either S3 or Glacier</li>
<li>RTO vs RPO</li>
<li>RTO or Recovery Time Objective is the length of time from which you can recover from a disaster</li>
<li>RTO is measured from when the disaster first occurred to when you have fully recovered from it</li>
<li>RPO or Recovery Point Objective is the amount of data your organization is prepared to lose in the event of a disaster</li>
<li>RPO examples are only allowing 1 day of email loss, or 5 hours of transaction records lost, 24 hours of backups, etc..</li>
<li>Typically the lower RTO and RPO thresholds that are set, the more costly the solution will be</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>DR Strategies:</strong></p>
</blockquote>
<ul>
<li>Pilot Light:</li>
<li>The term used to describe a DR scenario in which a minimal version of the environment is always running in the cloud</li>
<li>Similar to a backup and restore scenario. AWS can maintain a pilot light by configuring and running the most critical
    core elements of your system in AWS. When the time comes for recovery, the environment can quickly provision a full
    scale production environment around the critical core via auto-scaling and other measures. </li>
<li>Typically includes Databases, which could be replicated to RDS or EC2 instances along with any other critical core components</li>
<li>Rest of your infrastructure can be set up using pre-configured AMI's and Cloudformation</li>
<li>For networking, use pre-allocated EIP's and associate them with your instances when invoking DR, or use pre-allocated ENI's
    with pre-allocated MAC addresses for applications with special licensing requirements</li>
<li>Use ELBs to distribute traffic to multiple instances, and update DNS records to point at your EC2 instances or point to the ELB's using CNAME records</li>
<li>Warm Standby:</li>
<li>Used to describe a DR scenario in which a scaled down version of a fully functional environment is always running in the cloud</li>
<li>Extends the pilot light elements and decreases the recovery time because some services are always running</li>
<li>By identifying business critical systems, you can fully duplicate those systems on AWS and have them always on</li>
<li>Critical components can be running on minimum sized instances. The scenario is not scaled to handle production load, but is fully functional</li>
<li>Can be used for non production work, such as testing, QA and internal use</li>
<li>In a disaster, the system can be scaled horizontally or vertically quickly to handle production load</li>
<li>In AWS you can simply add more instances to the environment or by resizing the small capacity servers to run on larger instance types</li>
<li>Horizontal scaling is preferred over vertical scaling</li>
<li>To set up Warm Standby:<ul>
<li>Set up EC2 instances to replicate or mirror data</li>
<li>Create and maintain AMIs</li>
<li>Run your application using a minimal footprint of EC2 instances or AWS infrastructure</li>
<li>Patch and update software and configuration files in line with your environment</li>
<li>Increase the size of the EC2 fleet in service with the load balancer (horizontal scaling)</li>
<li>Start applications on larger EC2 instance types as needed (vertical scaling)</li>
<li>Either manually change the DNS records or use Route53's automated health checks so that all traffic is routed to the AWS environment</li>
<li>Consider using auto scaling to right size the fleet or accommodate the increased load</li>
<li>Add resilience or scale up your database</li>
</ul>
</li>
<li>Multi-Site:</li>
<li>Runs in AWS as well as your existing on-site infrastructure in an active active configuration</li>
<li>The data replication method that you employ will be determined by the recovery point that you choose</li>
<li>You can use Route53 to root traffic to both sites either symmetrically or asymmetrically</li>
<li>In an on-site disaster recovery situation, you can adjust the DNS weighting and send all traffic to AWS servers</li>
<li>The capacity of the AWS service can be rapidly increased to handle the full production load</li>
<li>You can use EC2 Auto scaling to automate the process</li>
<li>May need some application logic to detect the failure of the primary database service and cut over to the parallel database service running in AWS</li>
<li>To set up Multi-site Standby:</li>
<li>Set up AWS environment to duplicate your production environment</li>
<li>Set up DNS weighting or a similar traffic routing technology, to distribute incoming requests to both sites</li>
<li>Configure automatic failover to re-route traffic away from the affected site</li>
<li>Have application logic for failover to use the local AWS database servers for all queries</li>
<li>Move from DR Site back to primary site:<ul>
<li>Establish reverse mirroring / replication from the DR site back to the primary site</li>
<li>Wait for primary site to catch up to DR site</li>
<li>Freeze data changes to the DR site</li>
<li>Re-Point users back to the primary site</li>
<li>UnFreeze the changes</li>
</ul>
</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>Backups:</strong></p>
</blockquote>
<ul>
<li>Traditionally data is backed up to tape and sent off site regularly </li>
<li>Using the tape method can take a long time to restore your system in the event of a disaster</li>
<li>S3 is an ideal destination for backup data that might need to be restored quickly</li>
<li>Transferring data to and from S3 is typically done through the network and therefor accessible from any location</li>
<li>Can use AWS import/export to transfer very large data sets by shipping storage devices directly to AWS</li>
<li>For longer term data storage where retrieval times of several hours are adequate, Glacier can be leveraged</li>
<li>Glacier has the same durability model as S3, and can be used in conjunction with S3 to produce a tiered backup solution</li>
<li>Select an appropriate tool or method to backup your data to AWS</li>
<li>Ensure you have an appropriate retention policy for your data</li>
<li>Ensure that appropriate security measures are in place for the data including encryption and access policies</li>
<li>Regularly test the recovery and restoration of the data and applicable systems</li>
<li>Moving from DR back to Primary Site:</li>
<li>Freeze data changes to the DR site</li>
<li>Take backup</li>
<li>Restore the backup to the primary site</li>
<li>Re-point users to the primary site</li>
<li>Unfreeze changes</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>Services with automated backups:</strong></p>
</blockquote>
<ul>
<li>RDS</li>
<li>Need InnoDB (translated Engine)</li>
<li>Performance hit if Multi-AZ is not enabled</li>
<li>If you delete an instance, then ALL automated backups are deleted</li>
<li>Manual DB snapshots will NOT be deleted</li>
<li>All backups stored on S3</li>
<li>When you do a restore, you can change the engine type (SQL standard to SQL Enterprise for example), provided you have enough space</li>
<li>Elasticache (Redis Only)</li>
<li>Available for Redis Cache Cluster only</li>
<li>The entire cluster is snapshotted</li>
<li>Snapshots WILL degrade performance</li>
<li>Set the snapshot window during the least busy part of the day</li>
<li>All snapshots stored on S3</li>
<li>Redshift</li>
<li>By default Redshift enables automated backups of your data warehouse cluster with a 1 day retention</li>
<li>Redshift only backs up data that has changed, so most snapshots only use up a small amount of backup storage</li>
<li>All snapshots stored on S3</li>
<li>EC2 does NOT have automated backups (Can take snapshots, but they are not automated)</li>
<li>No automated backups</li>
<li>Backups degrade your performance, schedule these times during off peak hours</li>
<li>Can create automated backups using either the CLI interface or Python</li>
<li>Snapshots are Incremental:<ul>
<li>Snapshots only store incremental changes since the last snapshot</li>
<li>Only charged for incremental storage</li>
<li>Each snapshot still contains the base snapshot data</li>
</ul>
</li>
<li>All snapshots are stored on S3</li>
</ul>
<p><br></p>
<h1 id="ec2-ebs">EC2 &amp; EBS:</h1>
<hr />
<blockquote>
<p><strong>EC2:</strong></p>
</blockquote>
<ul>
<li>When EC2 was first launched all AMI's were backed by Instance store or Ephemeral storage</li>
<li>Ephemeral storage is non-persist or temporary storage</li>
<li>When an instance is shut down, even if turned back up, the the contents of the instance store, or ephemeral storage will be gone, and unaccessible</li>
<li>Stopping and restarting an instance moves the instance to another host, hence the lost data</li>
<li>EC2 eventually got the ability to attach EBS or Elastic Block Storage which allows for data persistence</li>
<li>There is NO way to flag data preservation on ephemeral storage, if the instance restarts, or the host experiences issues, you can incur data loss</li>
<li>2 types of Volumes</li>
<li>Root Volume:<ul>
<li>This is where your operating system is installed</li>
<li>Can either be EBS or Ephemeral</li>
<li>Max size is 10GB</li>
<li>EBS root device volume can be up to 1 or 2TB depending on OS</li>
<li>Delete on Terminate is the default value</li>
</ul>
</li>
<li>Additional Volumes:<ul>
<li>This can be your D:, E:, F: / dev/sdb, /dev/sdc, /dev/sdd etc..</li>
<li>Delete on Terminate is NOT the default value, additional volumes WILL persist after the instance is terminated and must be manually deleted</li>
</ul>
</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>EBS:</strong></p>
</blockquote>
<ul>
<li>Allows users to have data persistence</li>
<li>EBS volumes can be detached from an instance and attached to other instances without data loss</li>
<li>EBS volumes can only be attached to a single instance at a time</li>
<li>EBS root volumes are terminated/deleted by default when the EC2 instance is terminated</li>
<li>Termination/Deletion default behavior can be stopped by un-selecting the "Delete on Termination" option when creating the instance
  or by setting the deleteontermination flag to false using the command line at boot time</li>
<li>Non root EBS volumes attached to the instance are preserved if you delete the instance</li>
<li>Boot time is quicker using EBS, typically less than 1 minute, where Instance store volumes are generally less than 5 minutes</li>
<li>Must manually delete additional EBS volumes when an instance is terminated. Failure to do so will hold a storage charge for unattached non deleted volumes</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>Snapshots:</strong></p>
</blockquote>
<ul>
<li>Exist on S3, you do not have access to the snapshots directly, but on the backend they are stored on S3</li>
<li>Snapshots are point in time copies of volumes</li>
<li>Snapshots are incremental, only the blocks that have changed since your last snapshot are moved to S3</li>
<li>The first snapshot takes some time to create as its a full snapshot of the volume</li>
<li>To create a snapshot for EBS volumes that serve as root devices you should stop the instance before taking the snapshot</li>
<li>You can take a snapshot while the instance is running</li>
<li>You can create AMI's from both volumes and snapshots</li>
<li>You can change EBS volume sizes on the fly, including changing the size and storage type</li>
<li>Volumes will ALWAYS be in the same AZ as the EC2 instance</li>
<li>To move an EC2 volume from one AZ/Region to another, take a snapshot or an image of it and then copy it to the new AZ/Region</li>
<li>Snapshots of encrypted volumes are encrypted automatically</li>
<li>Volumes restored from encrypted snapshots are encrypted automatically</li>
<li>You can share snapshots, but only if they are unencrypted</li>
<li>Shared snapshots can be shared with other AWS accounts or made public</li>
</ul>
<p><br></p>
<h1 id="opsworks">Opsworks:</h1>
<hr />
<ul>
<li>Cloud based applications usually require a group of related resources that must be created and managed collectively</li>
<li>The collection of instances is called a stack</li>
<li>Opsworks provides a simple and straight forward way to create and manage stacks and their associated resources</li>
<li>Opsworks is an application management service that helps automate operational tasks like code deployment, software configurations, package installations, 
  database setups, and server scaling using Chef</li>
<li>Provides the flexibility to define your application architecture and resource configuration and handles the provisioning and management of your AWS resources for you</li>
<li>Includes automation to scale your application based on time or load, monitoring to help troubleshot and take automated actions based on the state of your resources</li>
<li>Handles permissions and policy management to make management of multi-user environments easier</li>
<li>Chef turns infrastructure into code</li>
<li>Can automate how you build, deploy, and manage your infrastructure</li>
<li>Allows infrastructure to become as versionalble, testable, and repeatable as application code</li>
<li>Chef server stores your recipes as well as other configuration data</li>
<li>The chef client is installed on each server, instance, container or networking device that you manage referred to as nodes</li>
<li>The client periodically polls the Chef server for the latest policy and state of the network, if anything is out of date, the client brings it up to date</li>
<li>Opsworks provides a GUI to deploy and configure your infrastructure quickly</li>
<li>Consists of 2 elements, Stacks and Layers</li>
<li>A stack is a container or group of resources such as ELBs, EC2 instances, RDS instances, etc</li>
<li>A layer exists within a stack and consists of things like a web application layer </li>
<li>Think of a stack as a virtual data center</li>
<li>Each function is a different layer, you can wrap up the full configuration of a component within a layer such as PHP, Apache, etc.. </li>
<li>Need 1 or more layer per stack</li>
<li>An instance must be assigned to at least 1 layer</li>
<li>Which Chef layers run, are determined by the layer the instance belongs to</li>
<li>There are pre-configured layers that will auto provision things such as Applications, Databases, Load balancing, or Caching</li>
<li>if you select an existing ELB to be used in a layer, Opsworks will remove any currently registered instances and then manages
  the ELB for you. If you use the ELB console to modify the configuration, the changes will NOT be permanent</li>
</ul>
<p><br></p>
<h1 id="security">Security:</h1>
<hr />
<blockquote>
<p><strong>Shared Security Model:</strong></p>
</blockquote>
<ul>
<li>AWS Responsibilities:</li>
<li>Securing the underlying infrastructure that supports the cloud</li>
<li>Protecting the global infrastructure that runs all of the services offered on AWS</li>
<li>All hardware, software, networking, and facilities that run AWS services</li>
<li>Security configuration of its products and services that are considered managed services<ul>
<li>DynamoDB</li>
<li>RDS</li>
<li>Redshift</li>
<li>EMR</li>
<li>Workspaces</li>
<li>Workmail</li>
<li>etc...</li>
</ul>
</li>
<li>Patching of managed service nodes</li>
<li>Antivirus for managed service nodes</li>
<li>Storage device decommissioning, with prevention of customer data exposure</li>
<li>AWS uses techniques detailed in DoD 5220.22-M or NIST 800-88 to destroy data as part of its decommissioning process</li>
<li>All decommissioned magnetic storage devices are degaussed and physically destroyed in accordance with industry standard practices</li>
<li>AWS corporate network is completely segregated from the AWS production network by means of complex network security devices</li>
<li>AWS provides protection against DDOS, Man in the Middle attacks, Ip Spoofing, Port Scanning and Packet Sniffing by other tenants</li>
<li>Different instances run on the same physical hardware and are isolated from each other via the Xen hypervisor</li>
<li>AWS has firewalls that reside in the hypervisor layer, between the physical network interface and the instances virtual interfaces</li>
<li>All network packets must pass through the firewall layer, ensuring that no instance has access to any other instance other than 
    what is intended. Instance traffic to other instances is treated the same as public internet traffic</li>
<li>Customer instances have no access to raw disk devices, but are presented instead with virtual disks</li>
<li>AWS proprietary disk virtualization automatically resets each block of storage used by customers so that one customers data is never
    unintentionally exposed to another</li>
<li>Memory allocated to guests is scrubbed or set to 0 by the hypervisor when it is unallocated from a guest</li>
<li>Unallocated memory is NEVER returned to the pool of free memory until the memory scrubbing process is complete</li>
<li>AWS Service compliance<ul>
<li>SOC 1/SSAE 16/ISAE 3402 (formerly SAS 70 Type II)</li>
<li>SOC2</li>
<li>SOC3</li>
<li>FISMA</li>
<li>DIACAP</li>
<li>FedRAMP</li>
<li>PCI DSS Level 1</li>
<li>ISO 27001</li>
<li>ISO 9001</li>
<li>ITAR</li>
<li>FIPS 140-2</li>
<li>HIPPA</li>
<li>Cloud Security Alliance (CSA)</li>
<li>Motion Picture Association of America (MPAA)</li>
</ul>
</li>
<li>AWS provides their annual certifications and compliance reports</li>
<li>User Responsibilities:</li>
<li>Anything that is put on the cloud or connects to the cloud</li>
<li>IAAS (Infrastructure as a service) components require the user to perform all security configuration and management tasks<ul>
<li>EC2</li>
<li>VPC</li>
<li>S3</li>
</ul>
</li>
<li>Account management and user access</li>
<li>MFA implementation</li>
<li>Communication to services using SSL/TLS</li>
<li>Logging of API/User activity via CloudTrail</li>
<li>Protecting data transmission via HTTPS using SSL</li>
<li>Obtaining permission from AWS to perform penetration testing and or port scanning against your AWS Nodes</li>
<li>All vulnerability scans, port scans, and penetration testing requests MUST be submitted in advance and approved by AWS</li>
<li>When requesting and granted permission for port scanning, scans must be limited to your own instances</li>
<li>Unauthorized port scans are a violation of the AWS Acceptable Use Policy</li>
<li>Checking Trusted Advisor (TA) recommendations for potential cost savings, system performance improvements, and potential security gaps</li>
<li>TA can provide alerts on security misconfiguration, such as open ports, public access to S3 buckets, user logging activities, lack of MFA, and more</li>
<li>Guest operating system on non-managed services such as EC2 are under the full control of the user</li>
<li>AWS does NOT have any login or access rights to your instances guest operating system</li>
<li>Configuration of EC2 firewall. The inbound firewall configured on each EC2 instances is set by default in deny-all mode</li>
<li>Users are fully responsible for explicitly opening the ports needed to allow inbound traffic to their instances</li>
<li>User is responsible for using AWS's provided encryption options to encrypt EBS volumes and their snapshots with AES-256 bit encryption<ul>
<li>Encryption occurs on the servers that host the EC2 instances and EBS storage</li>
<li>EBS Encryption is only available on EC2's bigger instance types such as the M, C, R, and G instance families</li>
</ul>
</li>
<li>SSL Termination on ELBs</li>
<li>Anything put on AWS assets including the raw data compliance</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>IAM Policies:</strong></p>
</blockquote>
<ul>
<li>Each IAM Policy must contain the Resource property</li>
<li>Policies consist of 3 main components, Action, Resource, and Effect</li>
<li>Effect - Whether the policy allows or denies access</li>
<li>Action  The list of actions that are allowed or denied by the policy</li>
<li>Resource  The list of resources on which the actions can occur</li>
<li>Condition (Optional)  The circumstances under which the policy grants permission</li>
<li>Roles are more secure than programmatic access, and should always be used as the first resort where possible</li>
<li>All IAM users should have MFA (Multi-Factor Authentication) enabled</li>
</ul>
<p><br></p>
<pre><code class="json">{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: {
    &quot;Effect&quot;: &quot;Allow&quot;,
    &quot;Action&quot;: &quot;s3:ListBucket&quot;,
    &quot;Resource&quot;: &quot;arn:aws:s3:::example_bucket&quot;
  }
}
</code></pre>

<p>This sample policy would allow a ListBucket Request to be performed on the example_bucket S3 bucket for example.</p>
<p><br></p>
<blockquote>
<p><strong>STS (Security Token Service):</strong></p>
</blockquote>
<ul>
<li>Grants users limited and temporary access to AWS resources</li>
<li>Users can come from 3 different sources:</li>
<li>Federation (Active Directory):<ul>
<li>Uses Security Assertion Markup Language (SAML)</li>
<li>Grants temporary access based off hte users AD credentials</li>
<li>Does not need to be an IAM user</li>
<li>Single sign on allows users to log into the AWS console without assigning IAM credentials</li>
</ul>
</li>
<li>Federation with Mobile Apps:<ul>
<li>Use Facebook, Amazon, Google, or other OpenID providers to log in</li>
</ul>
</li>
<li>Cross Account Access:<ul>
<li>Lets users from one AWS account access to resources in another AWS account</li>
</ul>
</li>
<li>Federation - Combining or joining a list of users in one domain with a list of users in another domain (Active Directory -&gt; IAM for example)</li>
<li>Identity Broker - A service that allows you to take an identity from Domain A and join it (federate it) to Domain B</li>
<li>Identity Store - Services like Active Directory, Facebook, Google, Amazon, etc..</li>
<li>Identities - A user of a service like Amazon, Facebook, Google, etc.. </li>
<li>Steps of Authentication:</li>
<li>User enters username/password</li>
<li>Application calls an Identity Broker. The broker is passed the username/password</li>
<li>The Identity Broker uses the organizations centralized authentication to validate the identity of the user (Think Active Directory)</li>
<li>The Identity Broker then calls the new GetFederationToken function using IAM credentials. The call must include an IAM policy and duration (1-36 hours),
    along with a policy that specifies the permissions to be granted to the temporary security credentials</li>
<li>STS confirms that the policy of the user making the call gives permission to create new tokens and then returns 4 values<ul>
<li>Access Key</li>
<li>Secret Access Key</li>
<li>Token</li>
<li>Duration of token</li>
</ul>
</li>
<li>Identity Broker returns the temporary security credentials to the requesting application</li>
<li>The requesting application uses the temporary security credentials and token to make requests to Amazon</li>
<li>Amazon uses IAM to verify that the credentials allow the requested operation on the given service using the given key</li>
<li>IAM provides the service with a allowed action to perform the requested operation</li>
<li>Steps in Simplicity:</li>
<li>Develop an Identity Broker to communicate with LDAP and AWS STS</li>
<li>Identity Broker should always authenticate with LDAP first, then the STS service</li>
<li>Application gets temporary access to AWS resources</li>
</ul>
<p><br></p>
<h1 id="route53">Route53:</h1>
<hr />
<blockquote>
<p><strong>DNS:</strong></p>
</blockquote>
<ul>
<li>DNS or Domain Name System is used to convert human friendly domain names into IP addresses</li>
<li>2 types of IP addresses:</li>
<li>IPv4<ul>
<li>32 bit address</li>
<li>4 billion different addresses (4,294,967,296)</li>
</ul>
</li>
<li>IPv6<ul>
<li>Created to solve depletion issue of IPv4 address space</li>
<li>128 bit address</li>
<li>340 undecillion addresses (340,282,366,920,938,463,463,374,607,431,768,211,456)</li>
</ul>
</li>
<li>Top Level Domains: Signified by the last word in a domain name</li>
<li>.com</li>
<li>.edu</li>
<li>.gov</li>
<li>.net</li>
<li>.io</li>
<li>etc</li>
<li>Controlled by the Internet Assigned Numbers Authority (IANA)</li>
<li>Stored in a root zone database which is a database of all available TLDs (Top Level Domains)</li>
<li>Database can be found at <a href="http://www.iana.org/domains/root/db">http://www.iana.org/domains/root/db</a></li>
<li>Domain Names:</li>
<li>All names in a given domain name have to be unique</li>
<li>DNS registrars are authority's that can assign domain names directly under one or more TLD's</li>
<li>Domains are registered with InterNIC, as service of ICANN, which enforces uniqueness of domain names across the internet</li>
<li>Each domain name becomes registered in a central database known as the WhoIS database</li>
<li>Popular domain registrars include godaddy.com, namecheap.com, Route53 etc..</li>
<li>SOA (Start of Authority) Records store information about:</li>
<li>Name of the server that supplied the data for the zone</li>
<li>Administrator of the zone</li>
<li>Current version of the data file</li>
<li>Number of seconds a secondary name server should wait before checking for updates</li>
<li>Number of seconds a secondary name server should wait before retrying a failed domain transfer</li>
<li>Maximum number of seconds that a secondary name server can use data before it must either be refreshed or expired</li>
<li>Default number of seconds for the TTL (Time to Live) on resource records</li>
<li>DNS Record Types:</li>
<li>NS or Name Server Records are used by TLD's to direct traffic to the content DNS server which contains the authoritative DNS records</li>
<li>A  or Address records are used by a computer to translate the name of the domain to an IP address</li>
<li>CNAMES or Canonical Names can be used to resolve one domain name to another<ul>
<li>CNAME's can't be used for naked domain names (zone apex). As such awsdocs.com must be either an A record or an Alias record</li>
</ul>
</li>
<li>Alias records are used to map resource record sets in your hosted zone to ELBs, CloudFront Distributions, or S3 Buckets that are configured as websites<ul>
<li>Alias records work like CNAME records in that you can map one DNS name to another target DNS name</li>
<li>Alias records can save time because Route53 automatically recognizes changes in the record set that the alias resource record set refers to</li>
<li>You are NOT charged for requests to Alias records, you ARE charged for requests to CNAMES, so using Alias records is cheaper</li>
</ul>
</li>
<li>TTL or Time to Live is the length that a DNS record is cached on either the resolving server or the users local PC. 
  The lower the TTL, the faster changes to DNS records take to propagate throughout the internet</li>
<li>ELBs do not have a pre-defined IPv4 address, DNS names are used for ELB resolution</li>
<li>Understand the difference between an Alias Record and a CNAME</li>
<li>Always use an Alias record over a CNAME where possible, as it's cheaper and faster</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>Route53 Routing Policies:</strong></p>
</blockquote>
<ul>
<li>Simple</li>
<li>Default routing policy when you create a new record set</li>
<li>Most commonly used when you have a single resource that performs a given function for your domain</li>
<li>Example would be a single web server that serves content for a single domain name</li>
<li>Weighted</li>
<li>Use to route traffic to multiple resources in proportions that you specify</li>
<li>Split traffic based on different weights assigned within the record set</li>
<li>Example would be sending 10% of user traffic to US-East-1 and the other 90% to US-East-2 </li>
<li>Latency</li>
<li>Use when you have resources in multiple locations and you want to route traffic to the resource that provides the least latency</li>
<li>Route traffic based on lowest network latency for your end users, such as sending requests to the region that will give the user the fasted response time</li>
<li>Create a resource record set for EC2 or ELB resources in each region that hosts your content. When Route53 receives a request for your content, it selects the
    latency resource record for the region that gives the user the lowest latency</li>
<li>Failover</li>
<li>Use when you want to configure active-passive failover</li>
<li>Example would be when you want your primary site to be in US-East-1, and a DR site in US-West-1</li>
<li>Route53 will monitor the health of our primary site using a health check</li>
<li>Health checks are not automatic and must be configured by the user</li>
<li>GeoLocation</li>
<li>Use when you want to route traffic based on the location of your users</li>
<li>Example would be ensuring that EU customers get routed to servers residing in the EU, and ensuring US customers get routed to servers residing in the US</li>
</ul>
<p><br></p>
<h1 id="vpcs-and-direct-connect">VPCs and Direct Connect:</h1>
<hr />
<blockquote>
<p><strong>VPC's:</strong></p>
</blockquote>
<p>Lets you provision a logically isolated section of the AWS Cloud where you can launch AWS resources in a virtual network that you define. 
You have complete control over your virtual networking, IP ranges, creation of subnets and configuration of route tables and network gateways. <br></p>
<ul>
<li>Virtual data center in the cloud</li>
<li>Allowed up to 5 VPCs in each AWS region by default. This limit can be increased with a support ticket request</li>
<li>All subnets in default VPC have an Internet gateway attached</li>
<li>Multiple IGW's can be created, but only a single IGW can be attached to a VPC.. No exceptions</li>
<li>Again, You can only have 1 Internet gateway per VPC</li>
<li>Each EC2 instance has both a public and private IP address</li>
<li>If you delete the default VPC, the only way to get it back is to submit a support ticket</li>
<li>This answer is correct for the current iteration of tests, however AWS has now crated a mechanism in the console that allows you to recreate a default VPC</li>
<li>By default when you create a VPC, a default main routing table automatically gets created as well.</li>
<li>Subnets are always mapped to a single AZ</li>
<li>Subnets can not be mapped to multiple AZ's</li>
<li>/16 is the largest CIDR block available when provisioning an IP space for a VPC</li>
<li>/28 is the smallest CIDR block available when provisioning an IP space for a VPC</li>
<li>Amazon uses 3 of the available IP addresses in a newly created subnet<ul>
<li>x.x.x.0 - Always subnet network address and is never usable</li>
<li>x.x.x.1 - Reserved by AWS for the VPC router</li>
<li>x.x.x.2 - Reserved by AWS for subnet DNS</li>
<li>x.x.x.3 - Reserved by AWS for future use</li>
<li>x.x.x.255 - Always subnet broadcast address and is never usable.</li>
</ul>
</li>
<li>169.254.169.253 - Amazon DNS</li>
<li>By default all traffic between subnets is allowed</li>
<li>By default not all subnets have access to the Internet. Either an Internet Gateway or NAT gateway is required for private subnets</li>
<li>A security group can stretch across different AZ's</li>
<li>Security Groups are stateful (Don't need to open inbound and outbound, if inbound is allowed, outbound is auto allowed)</li>
<li>Network Access Control Lists (NACLs) are stateless (Must define both inbound and outbound rules)</li>
<li>You can also create Hardware Virtual Private Network (VPN) connection between your corporate data center and your VPC and leverage the AWS cloud as an extension of your corporate data center</li>
<li>VPC Flow Logs:</li>
<li>VPC Flow Logs is a feature that enables the user to capture information about the IP traffic going to and from network interfaces in your VPC</li>
<li>Flow log data is stored using Cloudwatch Logs</li>
<li>When Flow log data is collected it can be viewed and its data can be retrieved within Cloudwatch</li>
<li>Flow logs can be created at 3 different levels, VPC, Subnet and Network Interface levels</li>
<li>Flow logs via Cloudwatch can be configured to stream to services such as Elasticache, or Lambda</li>
<li>You cannot enable flow logs for VPC's that are peered with your VPC unless the peer VPC is in your account</li>
<li>You cannot tag a flow log</li>
<li>After you have created a flow log, you cannot change its configuration, for example you cannot associate a different role with the flow log</li>
<li>Not all traffic is monitored:<ul>
<li>Traffic generated by instances when they contact Route53 is not monitored or logged</li>
<li>If you use your own DNS server, then all traffic to that DNS server is logged</li>
<li>Traffic generated by a Windows instance for Windows license activation is not monitored or logged</li>
<li>Traffic to and from the metadata service (169.254.169.254) is not monitored or logged</li>
<li>DHCP traffic is not monitored or logged</li>
<li>Traffic to the reserved IP address for the default VPC router is not monitored or logged</li>
</ul>
</li>
<li>Network Address Translation (NAT) Instances:<ul>
<li>When creating a NAT instance, disable Source/Destination checks on the instance or you could encounter issues</li>
<li>NAT instances must be in a public subnet</li>
<li>There must be a route out of the private subnet to the NAT instance in order for it to work</li>
<li>The amount of traffic that NAT instances support depend on the size of the NAT instance. If bottlenecked, increase the instance size</li>
<li>If you are experiencing any sort of bottleneck issues with a NAT instance, then increase the instance size</li>
<li>HA can be achieved by using Auto-scaling groups, or multiple subnets in different AZ's with a scripted fail-over procedure</li>
<li>NAT instances are always behind a security group</li>
</ul>
</li>
<li>Network Address Translation (NAT) Gateway:<ul>
<li>NAT Gateways scale automatically up to 10Gbps</li>
<li>There is no need to patch NAT gateways as the AMI is handled by AWS</li>
<li>NAT gateways are automatically assigned a public IP address</li>
<li>When a new NAT gateway has been created, remember to update your route table</li>
<li>No need to assign a security group, NAT gateways are not associated with security groups</li>
<li>Preferred in the Enterprise</li>
<li>No need to disable Source/Destination checks</li>
<li>More secure than a NAT instance</li>
</ul>
</li>
<li>Network Access Control Lists (NACLS):<ul>
<li>NACL's are stateless, meaning both inbound and outbound rules must be configured for traditional request/response model</li>
<li>Numbered list of rules that are evaluated in order starting at the lowest numbered rule first to determine what traffic is allowed in or out depending on what subnet is associated with the rule</li>
<li>The highest rule number is 32766</li>
<li>Start with rules starting at 100 so you can insert rules if needed</li>
<li>NACL's have separate inbound and outbound rules, and each rule can either allow or deny traffic</li>
<li>The Default NACL will allow ALL traffic in and out by default</li>
<li>Custom NACL's by default will deny all inbound and outbound traffic until allow rules are added</li>
<li>You must assign a NACL to each subnet, if a subnet is not associated with a NACL, it will allow no traffic in or out</li>
<li>NACL rules are stateless, established in does not create outbound rule automatically</li>
<li>You can only assign a single subnet to a single NACL</li>
<li>When you associate a NACL with a subnet, any previous associations are removed</li>
<li>You can associate a single NACL with multiple subnets</li>
<li>Each subnet in your VPC must be associated with a NACL. If you don't explicitly associate a subnet with an ACL, the subnet automatically gets
  associated with the default ACL</li>
<li>You can block IP addresses using NACLs not Security Groups</li>
</ul>
</li>
<li>VPC Peering:<ul>
<li>Connection between two VPCs that enables you to route traffic between them using private IP addresses via a direct network route</li>
<li>Instances in either VPC can communicate with each other as if they are within the same network</li>
<li>You can create VPC peering connections between your own VPCs or with a VPC in another account within a SINGLE REGION</li>
<li>AWS uses existing infrastructure of a VPC to create a VPC peering connection. It is not a gateway nor a VPN, and does not rely on separate hardware</li>
<li>There is NO single point of failure for communication nor any bandwidth bottleneck</li>
<li>There is no transitive peering between VPC peers (Can't go through 1 VPC to get to another)</li>
<li>Hub and spoke configuration model (1 to 1)</li>
<li>Be mindful of IPs in each VPC, if multiple VPCs have the same IP blocks, they will not be able to communicate</li>
<li>You can peer VPC's with other AWS accounts as well as with other VPCs in the same account</li>
</ul>
</li>
<li>VPC Endpoints:</li>
<li>Allows internal resources such as EC2 instances to reach various AWS services without having to traverse the public internet to get to the service</li>
<li>When you use an endpoint, the source IP address from your instances in your affected subnets for access the AWS service in the same region will use 
    private IP address's instead of public IP address's</li>
<li>When configuring VPC endpoints, existing connections from your affected subnets to the AWS service that use public IP address's may be dropped</li>
</ul>
<p><br></p>
<blockquote>
<p><strong>Direct Connect (DX):</strong></p>
</blockquote>
<ul>
<li>DX or Direct Connect makes it easy to establish a dedicated network connection from your premises to AWS</li>
<li>Using DX, you can establish private connectivity between AWs and your data center, office or collocation environment</li>
<li>Requires a dedicated line such as MPLS, or other circuit ran from tel-co.</li>
<li>From this line, you would have a cross connect from your on-premises device direct to AWS data centers</li>
<li>Using DX, can reduce network costs, increase bandwidth throughput and provide a more consistent network experience then internet based connections</li>
<li>Lets you establish a dedicated network connection between your network and one of the AWS DX locations</li>
<li>Uses industry standard 802.1Q VLANs</li>
<li>Dedicated connections can be partitioned into multiple virtual interfaces</li>
<li>Same connection can be used to access public resources such as objects stored in S3 using public IP's 
  and private resources such as EC2 instances running in a VPC using private IP's, all while
  maintaining network separation between the public and private environments</li>
<li>Virtual interfaces can be reconfigured at any time to meet changing needs</li>
<li>Offers more bandwidth and a more consistent network experience over using VPN based solutions</li>
<li>VPC VPN connections utilize IPSec to establish encrypted network connectivity between your intranet and your AWS VPC over the internet</li>
<li>VPN connections can be configured in minutes and are a good solution if you have an immediate need</li>
<li>DX does NOT involve the internet, instead, it uses dedicated private network connections between your intranet and AWS VPC</li>
</ul></div>
            </div>
        </div> <!-- /slidebar canvis area-->
